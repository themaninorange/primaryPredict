library(twittR)
library(twitteR)
help("twListToDF")
setwd('~/Dropbox/DataMining/Scraping/Visualization/tweets')
tweet_files <- list.files()
load(tweet_files[1])
View(Apr42016_Alabama)
load(tweet_files[1])
setwd('~/Dropbox/DataMining/Scraping/Visualization/tweets')
library(twitteR)
tweet_files <- list.files()
load(tweet_files[1])
View(Apr42016_Alabama)
rangle <- load(tweet_files[1])
rangle <- tweet_files[1]
dangle <- load(rangle)
length(tweet_files)
rm(Apr42016_Alabama)
for(i in 1:length(tweet_files)){
load(tweet_files[i])
}
setwd('~/Dropbox/DataMining/Scraping/Visualization/tweets')
tweet_files <- list.files()
for(i in 1:length(tweet_files)){
load(tweet_files[i])
}
library(twitteR)
setwd('~/Dropbox/DataMining/Scraping/Visualization/tweets')
tweet_files <- list.files()
for(i in 1:50){
load(tweet_files[i])
}
library(twitteR)
setwd('~/Dropbox/DataMining/Scraping/Visualization/tweets')
tweet_files <- list.files()
load(tweet_files[1])
library(twitteR)
setwd('~/Dropbox/DataMining/Scraping/Visualization/tweets')
tweet_files <- list.files()
for(i in 1:51){
load(tweet_files[i])
}
View(Apr42016_Alabama)
Apr42016_Alabama <- Apr42016_Alabama[-1, ]
View(Apr42016_Alabama)
View(Apr42016_Alaska)
AL.data <- load(tweet_files[1])
AL.data <- load(tweet_files[1])Apr42016_Alabama <- Apr42016_Alabama[-1, ]
AL.data <- load(tweet_files[1])
AL.data <- load(tweet_files[1])
AL.data <- load(tweet_files[1])
AL.data <- load(tweet_files[1])
setwd('~/Dropbox/DataMining/Scraping/Visualization/tweets')
tweet_files <- list.files()
AL.data <- load(tweet_files[1])
tweet_files <- list.files()
for(i in 1:50){
load(tweet_files[i])
}
View(Apr42016_Alabama)
dfs <- Filter(function(x) is(x, "data.frame"), mget(ls()))
dfs
data <- do.call(rbind, dfs)
rm(dfs)
head(data)
View(data)
which(data$text == 0)
data <- data[-which(data$text == 0), ]
?saveRDS
saveRDS(data, file = '~/Dropbox/DataMining/Scraping/Visualization/Results_Demographics_MJ/tweets.rds', )
save(data, file = '~/Dropbox/DataMining/Scraping/Visualization/Results_Demographics_MJ/tweets.rda', )
View(Apr92016_Wisconsin)
saveRDS(data, file = '~/Dropbox/DataMining/Scraping/Visualization/Results_Demographics_MJ/tweets.rda', )
View(data)
date_1 <- as.POSIXct(data$created[1], origin = "1970-01-01")
date_1
data$date <- as.POSIXct(data$created, origin = "1970-01-01")
rm(date_1)
row.names(data)
library(stringr)
substr(row.names(data), 1, 8)
data$date_collection <- substr(row.names(data), 1, 8)
library(tm)
twat.clean = function(twit.dat){
# First, get rid of hyperlinks
twit.dat$text.clean <- gsub("http[[:alnum:]]*", "", twit.dat$text)
# Not sure if necessary, but fuck it removing it anyways
twit.dat$text.clean = gsub('<.*?>', '', twit.dat$text.clean)
# Removing punctuation
twit.dat$text.clean = gsub('[[:punct:]]', '', twit.dat$text.clean)
# Removing Emojis and making everything text
twit.dat$text.clean = sapply(twit.dat$text.clean, function(row) iconv(row, "latin1", "ASCII",
sub = ""))
# Making everything lower case
twit.dat$text.clean = tolower(twit.dat$text.clean)
# Removing stopwords
twit.dat$text.clean = removeWords(twit.dat$text.clean, stopwords("en"))
}
saveRDS(data, file = '~/Dropbox/DataMining/Scraping/Visualization/Results_Demographics_MJ/tweets.rda', )
data <- twat.clean(data)
load(file = '~/Dropbox/DataMining/Scraping/Visualization/Results_Demographics_MJ/tweets.rda')
load("~/Dropbox/DataMining/Scraping/Visualization/Results_Demographics_MJ/tweets.rda")
setwd('~/Dropbox/DataMining/Scraping/Visualization/tweets')
tweet_files <- list.files()
for(i in 1:50){
load(tweet_files[i])
}
dfs <- Filter(function(x) is(x, "data.frame"), mget(ls()))
data <- do.call(rbind, dfs)
which(data$text == 0)
data <- data[-which(data$text == 0), ]
data$date <- as.POSIXct(data$created, origin = "1970-01-01")
data$date_collection <- substr(row.names(data), 1, 8)
data$text.clean <- twat.clean(data)
data <- do.call(rbind, dfs)
data <- data[-which(data$text == 0), ]
load(file = '~/Dropbox/DataMining/Scraping/Visualization/Results_Demographics_MJ/tweets.rda')
load(file = '~/Dropbox/DataMining/Scraping/Visualization/Results_Demographics_MJ/tweets.rds')
load("~/Dropbox/DataMining/Scraping/Visualization/Results_Demographics_MJ/tweets.rda")
View(data)
library(tm)
twat.clean = function(twit.dat){
# First, get rid of hyperlinks
twit.dat$text.clean <- gsub("http[[:alnum:]]*", "", twit.dat$text)
# Not sure if necessary, but fuck it removing it anyways
twit.dat$text.clean = gsub('<.*?>', '', twit.dat$text.clean)
# Removing punctuation
twit.dat$text.clean = gsub('[[:punct:]]', '', twit.dat$text.clean)
# Removing Emojis and making everything text
twit.dat$text.clean = sapply(twit.dat$text.clean, function(row) iconv(row, "latin1", "ASCII",
sub = ""))
# Making everything lower case
twit.dat$text.clean = tolower(twit.dat$text.clean)
# Removing stopwords
twit.dat$text.clean = removeWords(twit.dat$text.clean, stopwords("en"))
}
data$text.clean <- twat.clean(data)
save(data, file = '~/Dropbox/DataMining/Scraping/Visualization/Results_Demographics_MJ/tweets.rda', )
??save
save(data, file = '~/Dropbox/DataMining/Scraping/Visualization/Results_Demographics_MJ/tweets.rda')
colnames(data)
vis_data <- data[ , which(colnames(data) == 'text.clean' | colnames(data) == 'fips' | colnames(data) == 'keyword')]
View(vis_data)
row.names(vis_data) <- NULL
twat.clean = function(twit.dat){
# First, get rid of hyperlinks
twit.dat$text.clean <- gsub("http.*", "", twit.dat$text)
# Not sure if necessary, but fuck it removing it anyways
twit.dat$text.clean = gsub('<.*?>', '', twit.dat$text.clean)
# Removing punctuation
twit.dat$text.clean = gsub('[[:punct:]]', '', twit.dat$text.clean)
# Removing Emojis and making everything text
twit.dat$text.clean = sapply(twit.dat$text.clean, function(row) iconv(row, "latin1", "ASCII",
sub = ""))
# Making everything lower case
twit.dat$text.clean = tolower(twit.dat$text.clean)
# Removing stopwords
twit.dat$text.clean = removeWords(twit.dat$text.clean, stopwords("en"))
}
data$text.clean <- twat.clean(data)
twat.clean = function(twit.dat){
# First, get rid of hyperlinks
twit.dat$text.clean <- gsub("http.* ", "", twit.dat$text)
# Not sure if necessary, but fuck it removing it anyways
twit.dat$text.clean = gsub('<.*?>', '', twit.dat$text.clean)
# Removing punctuation
twit.dat$text.clean = gsub('[[:punct:]]', '', twit.dat$text.clean)
# Removing Emojis and making everything text
twit.dat$text.clean = sapply(twit.dat$text.clean, function(row) iconv(row, "latin1", "ASCII",
sub = ""))
# Making everything lower case
twit.dat$text.clean = tolower(twit.dat$text.clean)
# Removing stopwords
twit.dat$text.clean = removeWords(twit.dat$text.clean, stopwords("en"))
}
data$text.clean <- twat.clean(data)
data[11, 1]
twat.clean = function(twit.dat){
# First, get rid of hyperlinks
twit.dat$text.clean <- gsub("http.*[:space:]", "", twit.dat$text)
# Not sure if necessary, but fuck it removing it anyways
twit.dat$text.clean = gsub('<.*?>', '', twit.dat$text.clean)
# Removing punctuation
twit.dat$text.clean = gsub('[[:punct:]]', '', twit.dat$text.clean)
# Removing Emojis and making everything text
twit.dat$text.clean = sapply(twit.dat$text.clean, function(row) iconv(row, "latin1", "ASCII",
sub = ""))
# Making everything lower case
twit.dat$text.clean = tolower(twit.dat$text.clean)
# Removing stopwords
twit.dat$text.clean = removeWords(twit.dat$text.clean, stopwords("en"))
}
data$text.clean <- twat.clean(data)
twat.clean = function(twit.dat){
# Removing punctuation
twit.dat$text.clean = gsub('[[:punct:]]', '', twit.dat$text.clean)
# First, get rid of hyperlinks
twit.dat$text.clean <- gsub("http.* ", "", twit.dat$text)
# Not sure if necessary, but fuck it removing it anyways
twit.dat$text.clean = gsub('<.*?>', '', twit.dat$text.clean)
# Removing Emojis and making everything text
twit.dat$text.clean = sapply(twit.dat$text.clean, function(row) iconv(row, "latin1", "ASCII",
sub = ""))
# Making everything lower case
twit.dat$text.clean = tolower(twit.dat$text.clean)
# Removing stopwords
twit.dat$text.clean = removeWords(twit.dat$text.clean, stopwords("en"))
}
data$text.clean <- twat.clean(data)
twat.clean = function(twit.dat){
# Removing punctuation
twit.dat$text.clean = gsub('[[:punct:]]', '', twit.dat$text)
# First, get rid of hyperlinks
twit.dat$text.clean <- gsub("http.* ", "", twit.dat$text.clean)
# Not sure if necessary, but fuck it removing it anyways
twit.dat$text.clean = gsub('<.*?>', '', twit.dat$text.clean)
# Removing Emojis and making everything text
twit.dat$text.clean = sapply(twit.dat$text.clean, function(row) iconv(row, "latin1", "ASCII",
sub = ""))
# Making everything lower case
twit.dat$text.clean = tolower(twit.dat$text.clean)
# Removing stopwords
twit.dat$text.clean = removeWords(twit.dat$text.clean, stopwords("en"))
}
data$text.clean <- twat.clean(data)
twat.clean = function(twit.dat){
# Removing punctuation
twit.dat$text.clean = gsub('[[:punct:]]', '', twit.dat$text)
# First, get rid of hyperlinks
twit.dat$text.clean <- gsub("http[[:alnum:]] ", "", twit.dat$text.clean)
# Not sure if necessary, but fuck it removing it anyways
twit.dat$text.clean = gsub('<.*?>', '', twit.dat$text.clean)
# Removing Emojis and making everything text
twit.dat$text.clean = sapply(twit.dat$text.clean, function(row) iconv(row, "latin1", "ASCII",
sub = ""))
# Making everything lower case
twit.dat$text.clean = tolower(twit.dat$text.clean)
# Removing stopwords
twit.dat$text.clean = removeWords(twit.dat$text.clean, stopwords("en"))
}
data$text.clean <- twat.clean(data)
data$text.clean <- gsub("https[[:alnum:]] ", "", data$text.clean)
data$text.clean <- gsub("https[[:alpha:]] ", "", data$text.clean)
vis_data <- data[ , which(colnames(data) == 'text.clean' | colnames(data) == 'fips' | colnames(data) == 'keyword')]
row.names(vis_data) <- NULL
read.csv('~/Dropbox/DataMining/Scraping/Visualization/Results_Demographics_MJ/PrimaryResults.csv')
results <- read.csv('~/Dropbox/DataMining/Scraping/Visualization/Results_Demographics_MJ/PrimaryResults.csv')
save(data, file = '~/Dropbox/DataMining/Scraping/Visualization/Results_Demographics_MJ/tweets.rda')
rm(list=ls(all=TRUE))
load(file = '~/Dropbox/DataMining/Scraping/Visualization/Results_Demographics_MJ/tweets.rds')
library(twitteR)
setwd('~/Dropbox/DataMining/Scraping/Visualization/tweets')
load(file = '~/Dropbox/DataMining/Scraping/Visualization/Results_Demographics_MJ/tweets.rda')
results <- read.csv('~/Dropbox/DataMining/Scraping/Visualization/Results_Demographics_MJ/PrimaryResults.csv')
View(results)
??unique
results_dem <- results[which(results$party == 'Democrat'), ]
results_rep <- results[which(results$party == 'Republican'), ]
ncol(results_rep) + ncol(results_dem) == ncol(results)
8959 + 15652
nrow(results_rep) + nrow(results_dem) == nrow(results)
length(which(is.element(results_dem$candidate, c('Bernie Sanders', 'Hillary Clinton'))))
View(results_dem)
levels(results_dem$candidate)
is.factor(results_dem$candidate)
droplevels(results_dem$candidate)
results_dem$candidate <- droplevels(results_dem$candidate)
levels(results_dem$candidate)
length(which(results_dem$candidate == "Martin O'Malley"))
length(which(results_dem$candidate == "No Preference"))
length(which(results_dem$candidate == " No Preference"))
length(which(results_dem$candidate == " Uncommitted"))
unique(results_dem$fips)
results_dem_mj <- data.frame(unique(results_dem$fips))
View(results_dem_mj)
colnames(results_dem_mj) <- 'FIPS'
ncol(results_dem_mj)
ncol(results_dem_mj) <- length(levels(results_dem$candidate)) + 1
results_dem_mj[ ,levels(results_dem$candidate)] <- NA
colnames(results_dem_mj)
results_dem_mj <- results_dem_mj[ ,c(1, 5, 4, 6, 2, 3)]
colnames(results_dem_mj)
results_dem_mj[5, 'Hillary Clinton']
for(i in 1:nrow(results_dem_mj)){
for(j in colnames(results_dem_mj))
f <- results_dem_mj$FIPS[i]
results_dem_mj[i, j] <- results_dem$fraction_votes[which(results_dem$fips == f & results_dem$candidate == j)]
}
colnames(results_dem_mj) <- c('fips', 'Clinton', 'Sanders', 'OMalley', 'NoPref', 'Uncommitted')
for(i in 1:nrow(results_dem_mj)){
results_dem_mj$Clinton[i] <- results_dem$fraction_votes[which(results_dem$fips == results_dem_mj$fips[i] &
results_dem$candidate == 'Hillary Clinton')]
}
length(is.na(results_dem_mj$Clinton))
which(is.na(results_dem_mj$Clinton))
which(is.na(results_dem_mj$fips))
results_dem_mj <- results_dem_mj[!which(is.na(results_dem_mj$fips)), ]
which(is.na(results_dem_mj$fips))
for(i in 1:nrow(results_dem_mj)){
results_dem_mj$Clinton[i] <- results_dem$fraction_votes[which(results_dem$fips == results_dem_mj$fips[i] &
results_dem$candidate == 'Hillary Clinton')]
}
which(is.na(results_dem_mj$Clinton))
for(i in 1:nrow(results_dem_mj)){
results_dem_mj$Sanders[i] <- results_dem$fraction_votes[which(results_dem$fips == results_dem_mj$fips[i] &
results_dem$candidate == 'Bernie Sanders')]
}
results_dem_mj <- data.frame(unique(results_dem$fips))
colnames(results_dem_mj) <- 'FIPS'
results_dem_mj[ ,levels(results_dem$candidate)] <- NA
results_dem_mj <- results_dem_mj[ ,c(1, 5, 4, 6, 2, 3)]
colnames(results_dem_mj) <- c('fips', 'Clinton', 'Sanders', 'OMalley', 'NoPref', 'Uncommitted')
results_dem_mj <- results_dem_mj[!which(is.na(results_dem_mj$fips)), ]
results_dem_mj <- data.frame(unique(results_dem$fips))
colnames(results_dem_mj) <- 'FIPS'
results_dem_mj[ ,levels(results_dem$candidate)] <- NA
results_dem_mj <- results_dem_mj[ ,c(1, 5, 4, 6, 2, 3)]
colnames(results_dem_mj) <- c('fips', 'Clinton', 'Sanders', 'OMalley', 'NoPref', 'Uncommitted')
results_dem_mj <- results_dem_mj[-which(is.na(results_dem_mj$fips)), ]
for(i in 1:nrow(results_dem_mj)){
results_dem_mj$Clinton[i] <- results_dem$fraction_votes[which(results_dem$fips == results_dem_mj$fips[i] &
results_dem$candidate == 'Hillary Clinton')]
}
which(is.na(results_dem_mj$Clinton))
for(i in 1:nrow(results_dem_mj)){
results_dem_mj$Sanders[i] <- results_dem$fraction_votes[which(results_dem$fips == results_dem_mj$fips[i] &
results_dem$candidate == 'Bernie Sanders')]
}
levels(results_dem$candidate)
colnames(results_dem_mj)
for(i in 1:nrow(results_dem_mj)){
results_dem_mj$OMalley[i] <- results_dem$fraction_votes[which(results_dem$fips == results_dem_mj$fips[i] &
results_dem$candidate == "Martin O'Malley")]
}
for(i in 1:nrow(results_dem_mj)){
results_dem_mj$NoPref[i] <- results_dem$fraction_votes[which(results_dem$fips == results_dem_mj$fips[i] &
results_dem$candidate == ' No Preference')]
}
for(i in 1:nrow(results_dem_mj)){
results_dem_mj$Uncommitted[i] <- results_dem$fraction_votes[which(results_dem$fips == results_dem_mj$fips[i] &
results_dem$candidate == " Uncommitted")]
}
length(which(results_dem$candidate == ))
length(which(results_dem$candidate == " No Preference"))
results_dem_mj$OMalley <- 0
results_dem_mj$NoPref <- 0
results_dem_mj$Uncommitted <- 0
which(results_dem$candidate == " No Preference")
results_dem$fips[which(results_dem$candidate == " No Preference")]
results_dem[which(results_dem$candidate == " No Preference"), ]
